{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "IMDB_Data_in_Keras.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/gr3ybr0w/cookbook/blob/master/Machine_Learning/Neural_Networks/IMDB_Data_in_Keras.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "i-HfIXbDdIUz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "951b61d4-570b-4686-d089-9cfadab380a4"
      },
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/udacity/deep-learning.git"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'deep-learning'...\n",
            "remote: Counting objects: 1439, done.\u001b[K\n",
            "remote: Compressing objects: 100% (4/4), done.\u001b[K\n",
            "remote: Total 1439 (delta 0), reused 0 (delta 0), pack-reused 1435\u001b[K\n",
            "Receiving objects: 100% (1439/1439), 47.97 MiB | 25.00 MiB/s, done.\n",
            "Resolving deltas: 100% (602/602), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "IkI88qt9rBJ0",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Analyzing IMDB Data in Keras"
      ]
    },
    {
      "metadata": {
        "id": "VCQgEE1qdKd2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Imports\n",
        "import numpy as np\n",
        "import keras\n",
        "from keras.datasets import imdb\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "np.random.seed(42)\n",
        "from pprint import pprint"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "GVIUvM3srIXJ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 1. Loading the data\n",
        "This dataset comes preloaded with Keras, so one simple command will get us training and testing data. There is a parameter for how many words we want to look at. We've set it at 1000, but feel free to experiment."
      ]
    },
    {
      "metadata": {
        "id": "o6CHNuPXrDcH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "6abb477d-7eaf-42cf-c9e5-95df709698c3"
      },
      "cell_type": "code",
      "source": [
        "# Loading the data (it's preloaded in Keras)\n",
        "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=1000)\n",
        "\n",
        "print(x_train.shape)\n",
        "print(x_test.shape)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://s3.amazonaws.com/text-datasets/imdb.npz\n",
            "17465344/17464789 [==============================] - 4s 0us/step\n",
            "(25000,)\n",
            "(25000,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "tXVx6qYHrPh7",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 2. Examining the data\n",
        "Notice that the data has been already pre-processed, where all the words have numbers, and the reviews come in as a vector with the words that the review contains. For example, if the word 'the' is the first one in our dictionary, and a review contains the word 'the', then there is a 1 in the corresponding vector.\n",
        "\n",
        "The output comes as a vector of 1's and 0's, where 1 is a positive sentiment for the review, and 0 is negative."
      ]
    },
    {
      "metadata": {
        "id": "W-2IbZUPrLtH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 3740
        },
        "outputId": "d46e702d-f86b-4bf4-ff0c-4bed6e1827ab"
      },
      "cell_type": "code",
      "source": [
        "pprint(x_train[0])\n",
        "pprint(y_train[0])"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1,\n",
            " 14,\n",
            " 22,\n",
            " 16,\n",
            " 43,\n",
            " 530,\n",
            " 973,\n",
            " 2,\n",
            " 2,\n",
            " 65,\n",
            " 458,\n",
            " 2,\n",
            " 66,\n",
            " 2,\n",
            " 4,\n",
            " 173,\n",
            " 36,\n",
            " 256,\n",
            " 5,\n",
            " 25,\n",
            " 100,\n",
            " 43,\n",
            " 838,\n",
            " 112,\n",
            " 50,\n",
            " 670,\n",
            " 2,\n",
            " 9,\n",
            " 35,\n",
            " 480,\n",
            " 284,\n",
            " 5,\n",
            " 150,\n",
            " 4,\n",
            " 172,\n",
            " 112,\n",
            " 167,\n",
            " 2,\n",
            " 336,\n",
            " 385,\n",
            " 39,\n",
            " 4,\n",
            " 172,\n",
            " 2,\n",
            " 2,\n",
            " 17,\n",
            " 546,\n",
            " 38,\n",
            " 13,\n",
            " 447,\n",
            " 4,\n",
            " 192,\n",
            " 50,\n",
            " 16,\n",
            " 6,\n",
            " 147,\n",
            " 2,\n",
            " 19,\n",
            " 14,\n",
            " 22,\n",
            " 4,\n",
            " 2,\n",
            " 2,\n",
            " 469,\n",
            " 4,\n",
            " 22,\n",
            " 71,\n",
            " 87,\n",
            " 12,\n",
            " 16,\n",
            " 43,\n",
            " 530,\n",
            " 38,\n",
            " 76,\n",
            " 15,\n",
            " 13,\n",
            " 2,\n",
            " 4,\n",
            " 22,\n",
            " 17,\n",
            " 515,\n",
            " 17,\n",
            " 12,\n",
            " 16,\n",
            " 626,\n",
            " 18,\n",
            " 2,\n",
            " 5,\n",
            " 62,\n",
            " 386,\n",
            " 12,\n",
            " 8,\n",
            " 316,\n",
            " 8,\n",
            " 106,\n",
            " 5,\n",
            " 4,\n",
            " 2,\n",
            " 2,\n",
            " 16,\n",
            " 480,\n",
            " 66,\n",
            " 2,\n",
            " 33,\n",
            " 4,\n",
            " 130,\n",
            " 12,\n",
            " 16,\n",
            " 38,\n",
            " 619,\n",
            " 5,\n",
            " 25,\n",
            " 124,\n",
            " 51,\n",
            " 36,\n",
            " 135,\n",
            " 48,\n",
            " 25,\n",
            " 2,\n",
            " 33,\n",
            " 6,\n",
            " 22,\n",
            " 12,\n",
            " 215,\n",
            " 28,\n",
            " 77,\n",
            " 52,\n",
            " 5,\n",
            " 14,\n",
            " 407,\n",
            " 16,\n",
            " 82,\n",
            " 2,\n",
            " 8,\n",
            " 4,\n",
            " 107,\n",
            " 117,\n",
            " 2,\n",
            " 15,\n",
            " 256,\n",
            " 4,\n",
            " 2,\n",
            " 7,\n",
            " 2,\n",
            " 5,\n",
            " 723,\n",
            " 36,\n",
            " 71,\n",
            " 43,\n",
            " 530,\n",
            " 476,\n",
            " 26,\n",
            " 400,\n",
            " 317,\n",
            " 46,\n",
            " 7,\n",
            " 4,\n",
            " 2,\n",
            " 2,\n",
            " 13,\n",
            " 104,\n",
            " 88,\n",
            " 4,\n",
            " 381,\n",
            " 15,\n",
            " 297,\n",
            " 98,\n",
            " 32,\n",
            " 2,\n",
            " 56,\n",
            " 26,\n",
            " 141,\n",
            " 6,\n",
            " 194,\n",
            " 2,\n",
            " 18,\n",
            " 4,\n",
            " 226,\n",
            " 22,\n",
            " 21,\n",
            " 134,\n",
            " 476,\n",
            " 26,\n",
            " 480,\n",
            " 5,\n",
            " 144,\n",
            " 30,\n",
            " 2,\n",
            " 18,\n",
            " 51,\n",
            " 36,\n",
            " 28,\n",
            " 224,\n",
            " 92,\n",
            " 25,\n",
            " 104,\n",
            " 4,\n",
            " 226,\n",
            " 65,\n",
            " 16,\n",
            " 38,\n",
            " 2,\n",
            " 88,\n",
            " 12,\n",
            " 16,\n",
            " 283,\n",
            " 5,\n",
            " 16,\n",
            " 2,\n",
            " 113,\n",
            " 103,\n",
            " 32,\n",
            " 15,\n",
            " 16,\n",
            " 2,\n",
            " 19,\n",
            " 178,\n",
            " 32]\n",
            "1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "O3_MSlmFri-J",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 3. One-hot encoding the output\n",
        "Here, we'll turn the input vectors into (0,1)-vectors. For example, if the pre-processed vector contains the number 14, then in the processed vector, the 14th entry will be 1."
      ]
    },
    {
      "metadata": {
        "id": "c2ldYZ7crSJ2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 731
        },
        "outputId": "7b3babbc-f9eb-4bc0-a9ba-db2389830411"
      },
      "cell_type": "code",
      "source": [
        "# One-hot encoding the output into vector mode, each of length 1000\n",
        "tokenizer = Tokenizer(num_words=1000)\n",
        "x_train = tokenizer.sequences_to_matrix(x_train, mode='binary')\n",
        "x_test = tokenizer.sequences_to_matrix(x_test, mode='binary')\n",
        "print(x_train[0])"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0. 1. 1. 0. 1. 1. 1. 1. 1. 1. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 0.\n",
            " 0. 1. 1. 0. 1. 0. 1. 0. 1. 1. 0. 1. 1. 0. 1. 1. 0. 0. 0. 1. 0. 0. 1. 0.\n",
            " 1. 0. 1. 1. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 1. 1. 0. 0. 0. 0. 1.\n",
            " 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 1. 0. 0. 0. 1. 0. 0. 0.\n",
            " 0. 0. 1. 0. 1. 0. 0. 1. 1. 0. 1. 1. 0. 0. 0. 0. 1. 1. 0. 0. 0. 1. 0. 0.\n",
            " 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0.\n",
            " 1. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
            " 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.\n",
            " 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.\n",
            " 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.\n",
            " 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "9tVhfe6wruGB",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "And we'll also one-hot encode the output."
      ]
    },
    {
      "metadata": {
        "id": "zwBMrXIFroil",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "fc523e25-f9ab-4c12-8079-5b5eaa8fa632"
      },
      "cell_type": "code",
      "source": [
        "# One-hot encoding the output\n",
        "num_classes = 2\n",
        "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
        "print(y_train.shape)\n",
        "print(y_test.shape)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(25000, 2)\n",
            "(25000, 2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "14yhdVhOrznc",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 4. Building the  model architecture\n",
        "Build a model here using sequential. Feel free to experiment with different layers and sizes! Also, experiment adding dropout to reduce overfitting."
      ]
    },
    {
      "metadata": {
        "id": "cm66_H7nrwpn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f42c090a-b540-4dab-a522-8afc1d1d6498"
      },
      "cell_type": "code",
      "source": [
        "x_train.shape"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(25000, 1000)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "metadata": {
        "id": "-VaVxJHcr9m_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "3675b53f-8a76-401e-92fe-acc8a470f2b7"
      },
      "cell_type": "code",
      "source": [
        "y_train"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 1.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       ...,\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [1., 0.]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "metadata": {
        "id": "IdVX06icsFxu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "outputId": "bd1cfbb7-58c2-4c19-a2a5-d919c758030a"
      },
      "cell_type": "code",
      "source": [
        "# TODO: Build the model architecture\n",
        "# Building the model\n",
        "model = Sequential()\n",
        "model.add(Dense(2000, activation='relu', input_dim=1000))\n",
        "model.add(Dropout(.5))\n",
        "model.add(Dense(1000, activation='relu'))\n",
        "model.add(Dropout(.4))\n",
        "model.add(Dense(500, activation='relu'))\n",
        "model.add(Dropout(.3))\n",
        "model.add(Dense(2, activation='softmax'))\n",
        "\n",
        "# Compiling the model\n",
        "\n",
        "# TODO: Compile the model using a loss function and an optimizer.\n",
        "model.compile(loss = 'categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_1 (Dense)              (None, 2000)              2002000   \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 2000)              0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 1000)              2001000   \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 1000)              0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 500)               500500    \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 500)               0         \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 2)                 1002      \n",
            "=================================================================\n",
            "Total params: 4,504,502\n",
            "Trainable params: 4,504,502\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "uTjKDBHxsfhL",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 5. Training the model\n",
        "Run the model here. Experiment with different batch_size, and number of epochs!"
      ]
    },
    {
      "metadata": {
        "id": "zhiGk2t_sQhQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e9814012-2a1e-4cb5-8e2b-72073c9d91ad"
      },
      "cell_type": "code",
      "source": [
        "# TODO: Run the model. Feel free to experiment with different batch sizes and number of epochs.\n",
        "# Training the model\n",
        "model.fit(x_train, y_train, epochs=30, batch_size=50, verbose=0)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f97dc337160>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "metadata": {
        "id": "TejdsMIBssdj",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 6. Evaluating the model\n",
        "This will give you the accuracy of the model, as evaluated on the testing set. Can you get something over 85%?"
      ]
    },
    {
      "metadata": {
        "id": "JHvPe36Dsp0v",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "1e12b70a-08d3-4fad-fac6-7fa8347bf361"
      },
      "cell_type": "code",
      "source": [
        "score = model.evaluate(x_test, y_test, verbose=0)\n",
        "print(\"Accuracy: \", score[1])"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy:  0.85584\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "jaEF1--Rtv48",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}